{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "892e635c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import utils\n",
    "import rcnn\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from PIL import Image,ImageDraw\n",
    "import os\n",
    "import json\n",
    "from torchvision import transforms\n",
    "import skimage\n",
    "from train import train_step\n",
    "import torch.optim as optim\n",
    "\n",
    "epochs=4\n",
    "batch_size=16\n",
    "device='cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6489717",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Napoleon\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Napoleon\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model=rcnn.FasterRCNN(device=device,mode='train')\n",
    "model.to(device)\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "trainset=utils.MyDataset('./train',transform=transform)\n",
    "\n",
    "trainloader = DataLoader(dataset=trainset,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True,\n",
    "                         collate_fn=utils.collate_fn,\n",
    "                         drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "918c9157",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.01)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f625ba2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0\n",
      "item loss: 50.64851760864258\n",
      "box loss: 50.60029220581055\n",
      "logit loss: 0.04822378233075142\n",
      "item loss: 0.029400024563074112\n",
      "box loss: 0.0\n",
      "logit loss: 0.029400024563074112\n",
      "item loss: 0.03445080295205116\n",
      "box loss: 0.0\n",
      "logit loss: 0.03445080295205116\n",
      "item loss: 0.027668830007314682\n",
      "box loss: 0.0\n",
      "logit loss: 0.027668830007314682\n",
      "item loss: 41.61325454711914\n",
      "box loss: 41.573211669921875\n",
      "logit loss: 0.04004350304603577\n",
      "item loss: 50.426109313964844\n",
      "box loss: 50.38915252685547\n",
      "logit loss: 0.03695851191878319\n",
      "batch_loss: 19.36560821533203\n",
      "batch_logit_loss: 0.03511068969964981\n",
      "batch_box_loss: 19.547697067260742\n",
      "epoch  1\n",
      "item loss: 0.020691344514489174\n",
      "box loss: 0.0\n",
      "logit loss: 0.020691344514489174\n",
      "item loss: 49.367286682128906\n",
      "box loss: 49.340736389160156\n",
      "logit loss: 0.02654942311346531\n",
      "item loss: 70.84416961669922\n",
      "box loss: 70.80704498291016\n",
      "logit loss: 0.037122540175914764\n",
      "item loss: 24.23286247253418\n",
      "box loss: 24.179264068603516\n",
      "logit loss: 0.053598131984472275\n",
      "item loss: 0.019581587985157967\n",
      "box loss: 0.0\n",
      "logit loss: 0.019581587985157967\n",
      "item loss: 0.01957971416413784\n",
      "box loss: 0.0\n",
      "logit loss: 0.01957971416413784\n",
      "batch_loss: 19.44277000427246\n",
      "batch_logit_loss: 0.028117381036281586\n",
      "batch_box_loss: 19.632801055908203\n",
      "epoch  2\n",
      "item loss: 0.019583167508244514\n",
      "box loss: 0.0\n",
      "logit loss: 0.019583167508244514\n",
      "item loss: 52.85990905761719\n",
      "box loss: 52.8255729675293\n",
      "logit loss: 0.03433748334646225\n",
      "item loss: 0.019578907638788223\n",
      "box loss: 0.0\n",
      "logit loss: 0.019578907638788223\n",
      "item loss: 0.019579581916332245\n",
      "box loss: 0.0\n",
      "logit loss: 0.019579581916332245\n",
      "item loss: 74.86143493652344\n",
      "box loss: 74.82757568359375\n",
      "logit loss: 0.0338628888130188\n",
      "item loss: 0.019578879699110985\n",
      "box loss: 0.0\n",
      "logit loss: 0.019578879699110985\n",
      "batch_loss: 21.70891571044922\n",
      "batch_logit_loss: 0.02642766945064068\n",
      "batch_box_loss: 21.6824951171875\n",
      "epoch  3\n",
      "item loss: 0.01957889087498188\n",
      "box loss: 0.0\n",
      "logit loss: 0.01957889087498188\n",
      "item loss: 54.205387115478516\n",
      "box loss: 54.171077728271484\n",
      "logit loss: 0.0343082956969738\n",
      "item loss: 20.711288452148438\n",
      "box loss: 20.6916561126709\n",
      "logit loss: 0.019631996750831604\n",
      "item loss: 42.879093170166016\n",
      "box loss: 42.84151840209961\n",
      "logit loss: 0.03757505118846893\n",
      "item loss: 0.019578859210014343\n",
      "box loss: 0.0\n",
      "logit loss: 0.019578859210014343\n",
      "item loss: 0.019578859210014343\n",
      "box loss: 0.0\n",
      "logit loss: 0.019578859210014343\n",
      "batch_loss: 18.24547004699707\n",
      "batch_logit_loss: 0.025262022390961647\n",
      "batch_box_loss: 18.22020721435547\n",
      "finish!\n"
     ]
    }
   ],
   "source": [
    "model.mode='train'\n",
    "model.train()\n",
    "# 总共解决了几个问题：\n",
    "# 1、 训练结果预测输出全是背景；解决：需要对rpn网络进行正负样本平衡\n",
    "# 2、 训练过程中，box的损失波动较大；解决：去掉一些出界，过小的box，让用于回归训练的输出更加优质\n",
    "# \n",
    "for param in model.backbone.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for i in range(epochs):\n",
    "    print('epoch ',i)\n",
    "    batch_loss,batch_logit_loss,batch_box_loss=train_step(trainloader,model,optimizer,mode='total')\n",
    "    print('batch_loss:',batch_loss.item())\n",
    "    print('batch_logit_loss:',batch_logit_loss.item())\n",
    "    print('batch_box_loss:',batch_box_loss.item())\n",
    "    # box_loss.backward(retain_graph=True)\n",
    "    # optimizer.step()\n",
    "    # print('box loss:', box_loss.item())\n",
    "    #\n",
    "    # logit_loss.backward()\n",
    "    # optimizer.step()\n",
    "    # print('logit loss:', logit_loss.item())\n",
    "print('finish!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4dec87d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=Image.open('./val/angular_leafspot14.jpg')\n",
    "img=transform(img)\n",
    "img=img.unsqueeze(0)\n",
    "img=img.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be95055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0519637d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.mode='detect'\n",
    "model.eval()\n",
    "logits,boxes=model(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee3505e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=logits.max(dim=-1)[1].squeeze()\n",
    "\n",
    "target_boxes=boxes.squeeze()[torch.where(labels==1)[0]]\n",
    "target_logits=logits.squeeze()[torch.where(labels==1)[0]]\n",
    "target_logits=target_logits[:,1]\n",
    "display=target_logits.sort(descending=True)[1][0:20]\n",
    "display_boxes=target_boxes[display]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6db4ed39",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_for_drawing=Image.open('./val/angular_leafspot14.jpg')\n",
    "draw=ImageDraw.Draw(img_for_drawing)\n",
    "for i in range(len(display_boxes)):\n",
    "    draw.rectangle([(display_boxes[i][0],display_boxes[i][1]),(display_boxes[i][2],display_boxes[i][3])])\n",
    "img_for_drawing.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab384c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "image=trainset[3][0].unsqueeze(0)\n",
    "box=trainset[3][1]\n",
    "image=image.to(device)\n",
    "box=box.to(device)\n",
    "box=[box]\n",
    "logits,boxes=model(image,box)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e1904e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=logits.max(dim=-1)[1].squeeze()\n",
    "target_boxes=boxes.squeeze()[torch.where(labels==1)[0]]\n",
    "target_logits=logits.squeeze()[torch.where(labels==1)[0]]\n",
    "target_logits=target_logits[:,1]\n",
    "display=target_logits.sort(descending=True)[1][0:10]\n",
    "display_boxes=target_boxes[display]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "74756f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=image.to('cpu').squeeze().numpy()\n",
    "img=img.transpose(1,2,0)\n",
    "img*=255\n",
    "img=img.astype('uint8')\n",
    "img=Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "35121621",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw=ImageDraw.Draw(img)\n",
    "for i in range(len(display_boxes)):\n",
    "    # draw.rectangle([(boxes.squeeze()[i][0],boxes.squeeze()[i][1]),(boxes.squeeze()[i][2],boxes.squeeze()[i][3])])\n",
    "    # draw.rectangle([(target_boxes[i][0],target_boxes[i][1]),(target_boxes[i][2],target_boxes[i][3])])\n",
    "    draw.rectangle([(display_boxes[i][0],display_boxes[i][1]),(display_boxes[i][2],display_boxes[i][3])])\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e069c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.01,weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01606acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item loss: 0.6993722915649414\n",
      "item loss: 0.3465736210346222\n",
      "item loss: 0.3465736210346222\n",
      "item loss: 0.3465736210346222\n",
      "item loss: 0.3465736210346222\n",
      "item loss: 0.3465736210346222\n",
      "item loss: 0.3465736210346222\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [18], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(box)):\n\u001b[0;32m      8\u001b[0m     box[i]\u001b[38;5;241m=\u001b[39mbox[i]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 9\u001b[0m logit, reg, logit_loss,box_loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m total_loss\u001b[38;5;241m=\u001b[39mlogit_loss\u001b[38;5;241m+\u001b[39mbox_loss\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem loss:\u001b[39m\u001b[38;5;124m'\u001b[39m,total_loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Strawberry\\rcnn.py:170\u001b[0m, in \u001b[0;36mFasterRCNN.forward\u001b[1;34m(self, x, target)\u001b[0m\n\u001b[0;32m    168\u001b[0m _,_,w,h\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbox_num\u001b[38;5;241m=\u001b[39mw\u001b[38;5;241m*\u001b[39mh\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m9\u001b[39m\n\u001b[1;32m--> 170\u001b[0m \u001b[38;5;28mcls\u001b[39m,box,select_loss,box_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrpn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m,box,select_loss,box_loss\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Strawberry\\rcnn.py:59\u001b[0m, in \u001b[0;36mRPN.forward\u001b[1;34m(self, x, target)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# n为batch\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[1;32m---> 59\u001b[0m     temp \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIoU\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbox\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m     iou\u001b[38;5;241m.\u001b[39mappend(temp)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# iou的长度等于batch_size的长度\u001b[39;00m\n",
      "File \u001b[1;32m~\\Strawberry\\utils.py:171\u001b[0m, in \u001b[0;36mIoU\u001b[1;34m(box1, box2, batch_size)\u001b[0m\n\u001b[0;32m    169\u001b[0m     s_intersec \u001b[38;5;241m=\u001b[39m w \u001b[38;5;241m*\u001b[39m h\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;66;03m# s_intersec=s_intersec.unsqueeze(0).unsqueeze(2)\u001b[39;00m\n\u001b[1;32m--> 171\u001b[0m     iou \u001b[38;5;241m=\u001b[39m s_intersec \u001b[38;5;241m/\u001b[39m (\u001b[43ms_box1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ms_box2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ms_intersec\u001b[49m)\n\u001b[0;32m    172\u001b[0m     IoUs\u001b[38;5;241m.\u001b[39mappend(iou)\n\u001b[0;32m    173\u001b[0m IoUs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(IoUs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for param in model.backbone.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for i, data in enumerate(trainloader):\n",
    "    image, box = data\n",
    "    image=image.to(device)\n",
    "    for i in range(len(box)):\n",
    "        box[i]=box[i].to(device)\n",
    "    logit, reg, logit_loss,box_loss = model(image, box)\n",
    "    total_loss=logit_loss+box_loss\n",
    "    print('item loss:',total_loss.item())\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84507107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([], device='cuda:0', size=(0, 4), grad_fn=<IndexBackward0>),\n",
       " tensor([], device='cuda:0', size=(0, 4), grad_fn=<IndexBackward0>),\n",
       " tensor([], device='cuda:0', size=(0, 4), grad_fn=<IndexBackward0>),\n",
       " tensor([], device='cuda:0', size=(0, 4), grad_fn=<IndexBackward0>),\n",
       " tensor([], device='cuda:0', size=(0, 4), grad_fn=<IndexBackward0>),\n",
       " tensor([], device='cuda:0', size=(0, 4), grad_fn=<IndexBackward0>),\n",
       " tensor([], device='cuda:0', size=(0, 4), grad_fn=<IndexBackward0>),\n",
       " tensor([], device='cuda:0', size=(0, 4), grad_fn=<IndexBackward0>)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771f97bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b=boxes[0].max(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8e575b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cca36c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分别计算\n",
    "iou=IoU(reg[0],box[0],batch_size=1)\n",
    "#iou[1]=utils.IoU(reg,box[1],batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1e1e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7256a82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "box[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db32087b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target1=torch.where(iou>0.7)[1]# iou>0.7的\n",
    "target2=set(torch.where(iou[0]<0.3)[0])&set(torch.where(iou[1]<0.3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b871ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "target2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba215b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "target=torch.where((iou[1]<0.3)|(iou[1]>0.7))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed6e33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd5111e",
   "metadata": {},
   "outputs": [],
   "source": [
    "iou=iou[:,target]\n",
    "reg=reg[:,target,:]\n",
    "cls=cls[:,target,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d17836c",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive=torch.where(iou>0.7)[1]\n",
    "negtive=torch.where(iou<0.3)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc8d8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_label=torch.zeros(cls.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11fb961",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_label[0,positive,1]=1\n",
    "box_label[0,negtive,0]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcb6407",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.tensor([1,2,3])\n",
    "b=torch.tensor([2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e065d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.tensor([[0.2,0.3,1],[1,0.2,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a354eefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "target=torch.where(a>=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceec700",
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d02fff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=torch.rand(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce86db40",
   "metadata": {},
   "outputs": [],
   "source": [
    "b[target[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54701a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.unique(target[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4665ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "a>=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009cfeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a<=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f943d7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e4fd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74ccfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=1\n",
    "a+=b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4ee18d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
